hadoop commands:

1)sbin folder:
-> start-dfs.sh
-> start-yarn.sh
-> jps
		
2)if 6 nodes dont appear then go to bin directory,open terminal
-> hadoop namenode -format

3)sbin:
-> start-dfs.sh
-> start-yarn.sh
-> jps

4)sbin: 
->hdfs dfs -mkdir /{folder_name}

5) home: 
->open a terminal in home
->create a input.txt file(using command - 'touch {file name}.txt') 					(Eg. touch sarish.txt)

6)sbin:
->hadoop fs -put {file_path} /{folder_name}   									(Eg. fs -put /home/hadoop/sarish.txt /sarish_folder)
->yarn jar {path_of_mapreduce_jar_file} wordcount /{folder_name} /{output_folder_name}		(Eg. yarn jar /home/hadoop/hadoop-3.3.5/share/mapreduce/hadoop-mapreduce-example-3.3.5.jar wordcount...)
->hdfs dfs -cat /{output_folder_name}/part-r-00000

7)
->stop-all.sh


scala commands:

1) create file and add text 'amay.txt' (home directory)
2) start spark using
	>>   spark-shell
	>>   var x=sc.textFile('amay.txt')
	>>   var y=x.flatMap(_.split(" "))
	>>   var z=y.map((_,1))
	>>   var word_count=z.reduceByKey(_+_)
	>>   word_count.saveAsTextFile("output1")
	>>   word_count.foreach(println)